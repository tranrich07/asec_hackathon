{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('energy_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime to int\n",
    "df['time'] = pd.to_datetime(df['time'], utc=True).astype(int) / 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    " \n",
    "# Replace missing values using linear interpolation\n",
    "df = df.interpolate(method='linear', axis=0).ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrevelent columns\n",
    "\n",
    "# Drop columns with only zeros\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "# Drop empty columns\n",
    "df = df.dropna(how='all', axis=1)\n",
    "\n",
    "df2 = df\n",
    "\n",
    "# Drop forecast columns\n",
    "df = df.drop(columns=['forecast solar day ahead', 'forecast wind onshore day ahead', 'total load forecast', 'price day ahead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total load actual \n",
    "t = df['time']\n",
    "load = df['total load actual']\n",
    "\n",
    "plt.plot(t, load, label = \"total load actual\")\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total Load Actual')\n",
    "plt.title('Total Load Actual vs Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price actual\n",
    "t = df['time']\n",
    "price = df['price actual']\n",
    "\n",
    "plt.plot(t, price, label = \"price actual\")\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price Actual')\n",
    "plt.title('Price Actual vs Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection\n",
    "\n",
    "# Detection using interquartile range\n",
    "def iqr (s, k=1.5, thresholds=False):\n",
    "    # calculate interquartile range\n",
    "    q25, q75 = np.percentile(s, 25), np.percentile(s, 75)\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    # calculate the outlier cutoff\n",
    "    cut_off = iqr * k\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    \n",
    "    if thresholds:\n",
    "        return lower, upper\n",
    "    else:\n",
    "        # Identify outliers\n",
    "        return [True if x < lower or x > upper else False for x in s]\n",
    "\n",
    "# Create df showing outliers\n",
    "ds = df.drop(columns=['time'], axis=1)\n",
    "iqr_df = ds.apply(iqr, k=1.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with nulls\n",
    "for column in ds:\n",
    "    ds[column] = np.where(iqr_df[column] == True, 'NaN', ds[column])\n",
    "    \n",
    "cols = ds.columns\n",
    "ds[cols] = ds[cols].apply(pd.to_numeric, errors='coerce') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the nulls\n",
    "ds = ds.interpolate(method='linear', axis=0).ffill().bfill()\n",
    "df = pd.concat([df['time'], ds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with only zeros\n",
    "df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "# Drop colunms with the same values\n",
    "df = df.drop(df.std()[(df.std() == 0)].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create two models\n",
    "\n",
    "# 1. Predict 'total load actual'\n",
    "# 2. Predict 'price actual'\n",
    "\n",
    "df_load = df.drop(columns=['price actual'])\n",
    "df_price = df.drop(columns=['total load actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "\n",
    "# 70-30 split-----------------------------------\n",
    "\n",
    "# Number of rows\n",
    "num_row_l = len(df_load.index)\n",
    "num_row_p = len(df_price.index)\n",
    "\n",
    "# total actual load\n",
    "train_l = df_load.iloc[0:int(num_row_l*0.7)]\n",
    "test_l = df_load.iloc[int(num_row_l*0.7):]\n",
    "\n",
    "# price actual\n",
    "train_p = df_price.iloc[0:int(num_row_p*0.7)]\n",
    "test_p = df_price.iloc[int(num_row_p*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y (Actual Price / Load) vs X ------------------------------------------\n",
    "\n",
    "# total actual load\n",
    "X_train_l = train_l.iloc[:,0:len(df_load.columns)-1].values\n",
    "Y_train_l = train_l.iloc[:, len(df_load.columns)-1:].values\n",
    "\n",
    "X_test_l = test_l.iloc[:,0:len(df_load.columns)-1].values\n",
    "Y_test_l = test_l.iloc[:, len(df_load.columns)-1:].values\n",
    "\n",
    "# price actual\n",
    "X_train_p = train_p.iloc[:,0:len(df_price.columns)-1].values\n",
    "Y_train_p = train_p.iloc[:, len(df_price.columns)-1:].values\n",
    "\n",
    "X_test_p = test_p.iloc[:,0:len(df_price.columns)-1].values\n",
    "Y_test_p = test_p.iloc[:, len(df_price.columns)-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# total actual load\n",
    "X_train_l = scaler.fit_transform(X_train_l)\n",
    "Y_train_l = scaler.fit_transform(Y_train_l)\n",
    "\n",
    "X_test_l = scaler.fit_transform(X_test_l)\n",
    "Y_test_l = scaler.fit_transform(Y_test_l)\n",
    "\n",
    "# price actual\n",
    "X_train_p = scaler.fit_transform(X_train_p)\n",
    "Y_train_p = scaler.fit_transform(Y_train_p)\n",
    "\n",
    "X_test_p = scaler.fit_transform(X_test_p)\n",
    "Y_test_p = scaler.fit_transform(Y_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total actual load\n",
    "svclassifier_l = SVR(kernel='rbf')\n",
    "svclassifier_l.fit(X_train_l, Y_train_l.ravel())\n",
    "\n",
    "y_pred_l = svclassifier_l.predict(X_test_l)\n",
    "\n",
    "# price actual\n",
    "svclassifier_p = SVR(kernel='rbf')\n",
    "svclassifier_p.fit(X_train_p, Y_train_p.ravel())\n",
    "\n",
    "y_pred_p = svclassifier_p.predict(X_test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "# total actual load\n",
    "r_squared_l = r2_score(Y_test_l, y_pred_l)\n",
    "mae_l = mean_absolute_error(Y_test_l, y_pred_l)\n",
    "mse_l = mean_squared_error(Y_test_l, y_pred_l)\n",
    "rmse_l = np.sqrt(mse_l)\n",
    "print('Total Actual Load')\n",
    "print('R-Squared: ',r_squared_l)\n",
    "print('Mean Absolute Error: ',mae_l)\n",
    "print('Mean Squared Error: ',mse_l)\n",
    "print('Root Mean Squared Error: ',rmse_l)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# price actual\n",
    "r_squared_p = r2_score(Y_test_p, y_pred_p)\n",
    "mae_p = mean_absolute_error(Y_test_p, y_pred_p)\n",
    "mse_p = mean_squared_error(Y_test_p, y_pred_p)\n",
    "rmse_p = np.sqrt(mse_p)\n",
    "print('Price Actual')\n",
    "print('R-Squared: ',r_squared_p)\n",
    "print('Mean Absolute Error: ',mae_p)\n",
    "print('Mean Squared Error: ',mse_p)\n",
    "print('Root Mean Squared Error: ',rmse_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Predicted Model to Actual: Load\n",
    "\n",
    "fig, axis = plt.subplots(2)\n",
    "\n",
    "# time\n",
    "x_train_l = X_test_l[:,0:1]\n",
    "# total actual load (test)\n",
    "y_train_l = Y_test_l\n",
    "\n",
    "# Test Data Plot\n",
    "axis[0].plot(x_train_l, y_train_l)\n",
    "\n",
    "# Prediction Data Plot\n",
    "axis[1].plot(x_train_l, y_pred_l)\n",
    "\n",
    "axis[0].set_title('Test Data')\n",
    "axis[1].set_title('Predicted Data')\n",
    "\n",
    "axis[0].set(xlabel='Time', ylabel='Total Actual Load')\n",
    "axis[1].set(xlabel='Time', ylabel='Total Actual Load')\n",
    "\n",
    "plt.figure(figsize=(20, 10), dpi= 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Predicted Model to Actual: Load\n",
    "\n",
    "# time\n",
    "x_train_l = X_test_l[:,0:1]\n",
    "# total actual load (test)\n",
    "y_train_l = Y_test_l\n",
    "\n",
    "# Test Data Plot\n",
    "plt.plot(x_train_l, y_train_l, label='Test Data')\n",
    "\n",
    "# Prediction Data Plot\n",
    "plt.plot(x_train_l, y_pred_l, label='Predicted Data')\n",
    "\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Total Actual Load')\n",
    "plt.title('Comparison of Predicted Model to Actual: Load')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Predicted Model to Actual: Price\n",
    "\n",
    "fig, axis = plt.subplots(2)\n",
    "\n",
    "# time\n",
    "x_train_p = X_test_p[:,0:1]\n",
    "# total actual load (test)\n",
    "y_train_ = Y_test_p\n",
    "\n",
    "# Test Data Plot\n",
    "axis[0].plot(x_train_p, y_train_p)\n",
    "\n",
    "# Prediction Data Plot\n",
    "axis[1].plot(x_train_p, y_pred_p)\n",
    "\n",
    "axis[0].set_title('Test Data')\n",
    "axis[1].set_title('Predicted Data')\n",
    "\n",
    "axis[0].set(xlabel='Time', ylabel='Total Actual Load')\n",
    "axis[1].set(xlabel='Time', ylabel='Total Actual Load')\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Predicted Model to Actual: Price\n",
    "\n",
    "# time\n",
    "x_train_p = X_test_p[:,0:1]\n",
    "# price actual (test)\n",
    "y_train_p = Y_test_p\n",
    "\n",
    "# Test Data Plot\n",
    "plt.plot(x_train_p, y_train_p, label='Test Data')\n",
    "\n",
    "# Prediction Data Plot\n",
    "plt.plot(x_train_p, y_pred_p, label='Predict Data')\n",
    "\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price Actual')\n",
    "plt.title('Comparison of Predicted Model to Actual: Price')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
